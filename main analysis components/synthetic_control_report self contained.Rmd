---
title: "Synthetic Controls"
date: 'Report generated `r format(Sys.time(), "%A, %B %d, %Y")`'
output:
 html_document:
  toc: TRUE
  toc_float: TRUE
---

```{r setup, include = FALSE}
library('knitr', quietly = TRUE)
require(RCurl)
opts_chunk$set(echo = FALSE)
print(getwd())
```


```{r specify_inputs, include=TRUE}
#MOST DATES MUST BE IN FORMAT "YYYY-MM-01", exception is end of pre period, which is 1 day before end of post period
start_date        <- as.Date('2004-01-01') #Indicates the date of the first data point.
intervention_date <- as.Date('2009-12-31') #Indicates the date of intervention in the data.
end_date          <- as.Date('2013-12-01') #Indicates the date of the last data point.
pre_period        <- as.Date(c('2004-01-01', '2009-12-31')) #Range over which the data is trained for the CausalImpact model.
post_period       <- as.Date(c('2010-01-01', '2013-12-01')) #Range from the intervention date to the end date.
eval_period       <- as.Date(c('2012-01-01', '2013-12-01')) #Range over which rate ratio calculation will be performed.
year_def   <-'cal_year'  #Can be cal_year to aggregate results by Jan-Dec; 'epi_year' to aggregate July-June
sensitivity=TRUE
crossval=TRUE #run cross validation? Note this takes time...adds ~40 min with 10 age groups, 7 cores
group_name   <- 'age_group' #Name of column containing group labels.
date_name    <- 'date'      #Name of column containing dates.
outcome_name <- 'J12_18'    #Name of column containing outcome.
denom_name   <- 'ach_noj'   #Name of column containing denominator to be used in offset.
```


```{r setup_data, include=FALSE}
require(RCurl)
#Set the working directory
#This step only works as written if this file is run using the source() command. Otherwise, skip this step and set manually.

###WORKING DIRECTORY Should be set as the directory where .Rmd file is saved  ####
#setwd(auto.wd) ##automatically set working directory to '~desktop/synthetic-control-poisson-master/main analysis components/'
#setwd('C:/Users/dmw63/Documents/GitHub/synthetic-control-poisson/main analysis components')

#Used to check for relevant packages and update them if out of date or install them if not installed.
update_packages  <- TRUE #Whether to update outdated packages.
install_packages <- TRUE #Whether to install missing packages.
install_pandoc   <- TRUE #Whether to install pandoc, which requires an external installer, and rmarkdown, a package that depends on pandoc's successful installation.

#Assign variable values
country       <- 'Brazil' #Country or region name.
n_seasons     <- 12       #Number of months (seasons) per year. 12 for monthly, 4 for quarterly, 3 for trimester data.
exclude_covar <- c()      #User-defined list of covariate columns to exclude from all analyses.
exclude_group <- c()      #User-defined list of groups to exclude from analyses.
if(country=="Brazil"){code_change   <- TRUE     #Used for Brazil data. Set to TRUE to adjust for year 2008 coding changes; otherwise, set to FALSE.
    }else{
    code_change   <- FALSE
  }

input_directory  <- 'https://raw.githubusercontent.com/weinbergerlab/synthetic-control/master/Datasets%20for%20PNAS/' #Directory (or URL) containing input data file.
file_name="Dataset%20S1%20Brazil.csv"
output_directory <- '../Results'   #Directory where results will be saved.
output_directory <- paste(output_directory,'_',country,'_', format(Sys.time(), '%Y-%m-%d-%H%M%S'), '/', sep = '')                     #Adds a subfolder to output directory to organize results by date and time run.
data_file <- paste0(input_directory, file_name)
#prelog_data <- read.csv(data_file, check.names = FALSE)# IF IMPORTING FROM LOCAL
prelog_data <- read.csv(text=getURL(data_file), check.names = FALSE)# IF IMPORTING FROM URL
prelog_data<-prelog_data[!is.na(prelog_data[,outcome_name]),]#If outcome is missing, delete 
```




```{r analysis, include = FALSE}
source('./synthetic_control_functions.R', local=FALSE)
source('./synthetic_control_analysis.R', local=FALSE)
```

#`r country` Results

```{r sparse}
if (!is.null(names(sparse_groups[sparse_groups])) && length(names(sparse_groups[sparse_groups])) != 0) {
	kable(data.frame('Sparse Groups' = names(sparse_groups[sparse_groups]), check.names = FALSE), align = 'c')
}
```

##combine estimates
```{r Comparison of estimates from different models}
if (crossval){
kable( cbind.data.frame(rr_mean_stack_intervals,rr_mean_full_intervals,rr_mean_time_intervals,rr_mean_time_no_offset_intervals, rr_mean_pca_intervals), align = 'c')
}else{
kable( cbind.data.frame(rr_mean_best_intervals,rr_mean_full_intervals,rr_mean_time_intervals,rr_mean_time_no_offset_intervals, rr_mean_pca_intervals), align = 'c')  
}
```

##Plot of Rate ratios, with size proportional to cross validation weights
```{r fig.width=5, fig.height=3, fig.align = "center", dpi=300, echo=FALSE}
#Compare rate ratios, with size of marker scaled to cross val weights
		ggplot(rr_mean_combo, aes(x=group.index, y=mean.rr, color=Model,group=Model)) + 
	  geom_errorbar(aes(ymin=lcl, ymax=ucl), colour="gray", width=.0) +
	  geom_point(aes(shape=Model, size=est.index))+
     scale_shape_manual(values=c(15, 16, 17,18))+
	  scale_size_manual(values=c(point.weights2$value*2)) + #Scales area, which is optimal for bubbl plot
	  #geom_errorbar(rr_mean_combo,aes(ymin=lcl, ymax=ucl), colour="black", width=.1) +
	  theme_bw() +
	  guides(size=FALSE)+ #turn off size axis
	  scale_colour_manual(values=cbPalette)+
	  labs(x = "Group", y="Rate ratio")+
	  geom_hline(yintercept = 1, colour='gray',linetype = 2)+
	  theme(axis.line = element_line(colour = "black"),
	        legend.position=c(0.2, 0.9),
	        panel.grid.major = element_blank(),
	        panel.grid.minor = element_blank(),
	        panel.border = element_blank(),
	        panel.background = element_blank()) 
```

##Weights for each of the models from cross validation
```{r Comparison of Cross validation Weights from different models}
if(crossval){
kable(stacking_weights.all, align = 'c')
} else{
      print("Cross-validation not performed")
    }
```
  
##Number of variables selected in SC analysis
```{r modelsize}
kable(model.size.sc, col.names=c('Model Size'))
```

##Inclusion Probabilities
```{r incl, include = FALSE}
incl_probs <- NULL
	for (group in groups) {
	    incl_prob=impact_full[[group]]$inclusion_probs[-c(1:(n_seasons-1)),]
	    incl_prob<- incl_prob[order(-incl_prob$inclusion_probs),]
	    incl_prob<-incl_prob[c(1:3),]
	    incl_prob2<-incl_prob[,2]
	    incl_prob_names=incl_prob[,1]
			incl_prob3 <- data.frame('Group' = group, 'Greatest Inclusion Variable' = incl_prob_names[1], 'Greatest Inclusion Probability' = incl_prob2[1], 'Second Greatest Inclusion Variable' = incl_prob_names[2], 'Second Greatest Inclusion Probability' = incl_prob2[2], 'Third Greatest Inclusion Variable' = incl_prob_names[3], 'Third Greatest Inclusion Probability' = incl_prob2[3], check.names = FALSE)
			incl_probs <- rbind(incl_probs, incl_prob3)
		}
rownames(incl_probs) <- NULL
```

```{r incl_table}
kable(incl_probs, align = 'c')
```

##Weight Sensitivity Analysis
```{r sensitivity}
if (exists('sensitivity_table_intervals')) {
kable(sensitivity_table_intervals, align = 'c')
}
```


##Plots
```{r plots,fig.height =3 , fig.width = 5, fig.align = "center", dpi=300,results = 'asis'}
source('./synthetic_control_plot.R', local=FALSE)
```

##Print results
```{r save_results, echo=FALSE}
source('./synthetic_control_write_results.R', local = FALSE)

```